{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/07 22:17:45 WARN Utils: Your hostname, arkadia-355.local resolves to a loopback address: 127.0.0.1; using 10.0.1.12 instead (on interface en0)\n",
      "23/05/07 22:17:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/07 22:17:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/07 22:17:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('type', types.StringType(), True), \n",
    "    types.StructField('key', types.StringType(), True), \n",
    "    types.StructField('revision', types.IntegerType(), True), \n",
    "    types.StructField('last_modified', types.TimestampType(), True), \n",
    "    types.StructField('json', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .option(\"header\", \"false\")\n",
    "    .schema(schema)\n",
    "    .csv(\"ol_dump_authors_latest.txt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/07 22:18:02 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "23/05/07 22:18:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/05/07 22:18:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/05/07 22:18:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/05/07 22:18:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/05/07 22:18:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/05/07 22:18:15 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "23/05/07 22:18:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "23/05/07 22:18:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "23/05/07 22:18:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "23/05/07 22:18:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet(\"ol/authors/latest\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"ol/authors/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- revision: integer (nullable = true)\n",
      " |-- last_modified: timestamp (nullable = true)\n",
      " |-- json: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[type: string, key: string, revision: int, last_modified: timestamp, json: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------+--------------------+--------------------+\n",
      "|        type|                 key|revision|       last_modified|                json|\n",
      "+------------+--------------------+--------+--------------------+--------------------+\n",
      "|/type/author| /authors/OL5774906A|       1|2008-10-23 08:03:...|{\"name\": \"Guoxian...|\n",
      "|/type/author| /authors/OL4946143A|       1|2008-09-22 13:35:...|{\"name\": \"Shi Mao...|\n",
      "|/type/author| /authors/OL1434023A|       3|2011-06-19 09:07:...|{\"photos\": [67761...|\n",
      "|/type/author| /authors/OL9990392A|       1|2021-12-26 06:16:...|{\"type\": {\"key\": ...|\n",
      "|/type/author|/authors/OL10974596A|       1|2022-11-21 15:14:...|{\"type\": {\"key\": ...|\n",
      "|/type/author| /authors/OL4242464A|       1|2008-04-30 20:50:...|{\"name\": \"Syed M....|\n",
      "|/type/author| /authors/OL6794328A|       1|2010-03-27 04:49:...|{\"name\": \"Mark M....|\n",
      "|/type/author|/authors/OL11034476A|       1|2022-11-23 15:02:...|{\"type\": {\"key\": ...|\n",
      "|/type/author|/authors/OL10627480A|       1|2022-08-18 16:24:...|{\"type\": {\"key\": ...|\n",
      "|/type/author|/authors/OL12407631A|       1|2023-01-18 05:44:...|{\"type\": {\"key\": ...|\n",
      "|/type/author|/authors/OL10051740A|       1|2021-12-29 04:44:...|{\"type\": {\"key\": ...|\n",
      "|/type/author|  /authors/OL567231A|       1|2008-04-01 03:28:...|{\"name\": \"Singh, ...|\n",
      "|/type/author| /authors/OL7882218A|       1|2020-05-11 05:07:...|{\"name\": \"Regina ...|\n",
      "|/type/author| /authors/OL7497208A|       1|2019-04-05 15:49:...|{\"name\": \"Darlis ...|\n",
      "|/type/author|/authors/OL10684971A|       1|2022-09-18 20:51:...|{\"type\": {\"key\": ...|\n",
      "|/type/author| /authors/OL7361498A|       1|2016-12-05 11:25:...|{\"name\": \"Annie K...|\n",
      "|/type/author| /authors/OL6917084A|       1|2011-06-29 23:17:...|{\"name\": \"Robert ...|\n",
      "|/type/author|/authors/OL11491289A|       1|2022-12-07 22:00:...|{\"type\": {\"key\": ...|\n",
      "|/type/author| /authors/OL8644925A|       1|2020-10-18 09:50:...|{\"name\": \"Davide ...|\n",
      "|/type/author|/authors/OL11686385A|       1|2022-12-13 15:58:...|{\"type\": {\"key\": ...|\n",
      "+------------+--------------------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, from_json, explode_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = types.StructType([types.StructField(\"name\", types.StringType(), True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/51070251/pyspark-explode-json-in-column-to-multiple-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------+--------------------+\n",
      "|        type|                 key|                name|revision|       last_modified|\n",
      "+------------+--------------------+--------------------+--------+--------------------+\n",
      "|/type/author| /authors/OL5774906A|        Guoxiang Liu|       1|2008-10-23 08:03:...|\n",
      "|/type/author| /authors/OL4946143A|            Shi Mao.|       1|2008-09-22 13:35:...|\n",
      "|/type/author| /authors/OL1434023A|Nathan Altshiller...|       3|2011-06-19 09:07:...|\n",
      "|/type/author| /authors/OL9990392A|      Thisbe Gensler|       1|2021-12-26 06:16:...|\n",
      "|/type/author|/authors/OL10974596A|Foreword by Morri...|       1|2022-11-21 15:14:...|\n",
      "|/type/author| /authors/OL4242464A|      Syed M. Sarwar|       1|2008-04-30 20:50:...|\n",
      "|/type/author| /authors/OL6794328A|   Mark M. Yarbrough|       1|2010-03-27 04:49:...|\n",
      "|/type/author|/authors/OL11034476A|North Florida Ama...|       1|2022-11-23 15:02:...|\n",
      "|/type/author|/authors/OL10627480A|   Alonso Santosario|       1|2022-08-18 16:24:...|\n",
      "|/type/author|/authors/OL12407631A|        Robin Stacey|       1|2023-01-18 05:44:...|\n",
      "|/type/author|/authors/OL10051740A|   Mirja Brandenburg|       1|2021-12-29 04:44:...|\n",
      "|/type/author|  /authors/OL567231A|        Singh, S. P.|       1|2008-04-01 03:28:...|\n",
      "|/type/author| /authors/OL7882218A|     Regina Schuller|       1|2020-05-11 05:07:...|\n",
      "|/type/author| /authors/OL7497208A|    Darlis A. Miller|       1|2019-04-05 15:49:...|\n",
      "|/type/author|/authors/OL10684971A|     Lauren Varnadoe|       1|2022-09-18 20:51:...|\n",
      "|/type/author| /authors/OL7361498A|        Annie Kelsey|       1|2016-12-05 11:25:...|\n",
      "|/type/author| /authors/OL6917084A|     Robert Northoff|       1|2011-06-29 23:17:...|\n",
      "|/type/author|/authors/OL11491289A|Sadyebeth and Ans...|       1|2022-12-07 22:00:...|\n",
      "|/type/author| /authors/OL8644925A|         Davide Piga|       1|2020-10-18 09:50:...|\n",
      "|/type/author|/authors/OL11686385A|           Phạm Hùng|       1|2022-12-13 15:58:...|\n",
      "+------------+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"json\", from_json(\"json\", json_schema)).select(\n",
    "    \"type\",\n",
    "    \"key\",\n",
    "    \"json.name\",\n",
    "    \"revision\",\n",
    "    \"last_modified\"\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`type` is redundant so we can leave that out when selecting pertinent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
